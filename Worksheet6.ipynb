{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Task 1\n",
        "import numpy as np\n",
        "\n",
        "def logistic_function(x):\n",
        "    \"\"\"\n",
        "    Computes the logistic (sigmoid) function.\n",
        "    \"\"\"\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "print(\"Sigmoid Outputs:\")\n",
        "print(\"sigmoid(0)   =\", logistic_function(0))\n",
        "print(\"sigmoid(2)   =\", logistic_function(2))\n",
        "print(\"sigmoid(-3)  =\", logistic_function(-3))\n",
        "print(\"sigmoid([0,2,-3]) =\", logistic_function(np.array([0, 2, -3])))\n",
        "\n",
        "def test_logistic_function():\n",
        "    assert round(logistic_function(0), 3) == 0.5\n",
        "    assert round(logistic_function(2), 3) == 0.881\n",
        "    assert round(logistic_function(-3), 3) == 0.047\n",
        "\n",
        "    x_array = np.array([0, 2, -3])\n",
        "    expected = np.array([0.5, 0.881, 0.047])\n",
        "    assert np.all(np.round(logistic_function(x_array), 3) == expected)\n",
        "\n",
        "test_logistic_function()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYLF0dLSlFdk",
        "outputId": "1128ad72-5e4d-45fc-d38b-d8a50bdec08c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid Outputs:\n",
            "sigmoid(0)   = 0.5\n",
            "sigmoid(2)   = 0.8807970779778823\n",
            "sigmoid(-3)  = 0.04742587317756678\n",
            "sigmoid([0,2,-3]) = [0.5        0.88079708 0.04742587]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Log Loss\n",
        "def log_loss(y_true, y_pred):\n",
        "    y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
        "    return -(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n",
        "\n",
        "print(\"Log Loss Outputs:\")\n",
        "print(\"log_loss(1, 0.9) =\", log_loss(1, 0.9))\n",
        "print(\"log_loss(0, 0.1) =\", log_loss(0, 0.1))\n",
        "\n",
        "assert np.isclose(log_loss(1,1), 0.0)\n",
        "assert np.isclose(log_loss(0,0), 0.0)\n",
        "assert np.isclose(log_loss(1,0.8), -np.log(0.8))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0qTq3IPlxj2",
        "outputId": "3b4c9d1a-c646-4c7e-a369-795e1abc47ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Loss Outputs:\n",
            "log_loss(1, 0.9) = 0.10536051565782628\n",
            "log_loss(0, 0.1) = 0.10536051565782628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3: Cost Function\n",
        "def cost_function(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    loss = -(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n",
        "    return np.sum(loss) / n\n",
        "\n",
        "y_true = np.array([1,0,1])\n",
        "y_pred = np.array([0.9,0.1,0.8])\n",
        "print(\"Cost =\", cost_function(y_true, y_pred))\n",
        "\n",
        "expected = ( -np.log(0.9) - np.log(0.9) - np.log(0.8) ) / 3\n",
        "assert np.isclose(cost_function(y_true, y_pred), expected)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dxYvv0ll6a1",
        "outputId": "6eb4667c-843f-4af7-ee32-94b660d69424"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost = 0.14462152754328741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4: Logistic Regression Cost\n",
        "def costfunction_logreg(X, y, w, b):\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = logistic_function(z)\n",
        "    return cost_function(y, y_pred)\n",
        "\n",
        "X = np.array([[10,20],[-10,10]])\n",
        "y = np.array([1,0])\n",
        "w = np.array([0.5,1.5])\n",
        "b = 1\n",
        "print(\"Logistic Cost =\", costfunction_logreg(X,y,w,b))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx22LN5-mArd",
        "outputId": "eb7ac50a-edf8-4472-b396-93e6442b2842"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Cost = 5.500008350784906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 5: Gradient Computation\n",
        "def compute_gradient(X, y, w, b):\n",
        "    n = X.shape[0]\n",
        "    z = np.dot(X, w) + b\n",
        "    y_pred = logistic_function(z)\n",
        "    error = y_pred - y\n",
        "    grad_w = np.dot(X.T, error) / n\n",
        "    grad_b = np.sum(error) / n\n",
        "    return grad_w, grad_b\n",
        "\n",
        "grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "print(\"Gradient w =\", grad_w)\n",
        "print(\"Gradient b =\", grad_b)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLjTBHb_mPWR",
        "outputId": "ff3970eb-cd69-4a2e-c22f-f5d0058d9703"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient w = [-4.99991649  4.99991649]\n",
            "Gradient b = 0.4999916492890759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 6: Gradient Descent\n",
        "def gradient_descent(X, y, w, b, alpha, n_iter):\n",
        "    cost_history = []\n",
        "    for _ in range(n_iter):\n",
        "        grad_w, grad_b = compute_gradient(X, y, w, b)\n",
        "        w -= alpha * grad_w\n",
        "        b -= alpha * grad_b\n",
        "        cost_history.append(costfunction_logreg(X,y,w,b))\n",
        "    return w, b, cost_history\n",
        "\n",
        "X = np.array([[0.1,0.2],[-0.1,0.1]])\n",
        "y = np.array([1,0])\n",
        "w = np.zeros(2)\n",
        "b = 0.0\n",
        "\n",
        "w,b,cost_history = gradient_descent(X,y,w,b,0.1,100)\n",
        "print(\"Final w =\", w)\n",
        "print(\"Final b =\", b)\n",
        "print(\"Initial Cost =\", cost_history[0])\n",
        "print(\"Final Cost =\", cost_history[-1])\n",
        "\n",
        "assert cost_history[-1] < cost_history[0]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp7wvR61mUBC",
        "outputId": "7a15e695-7ff0-4bf8-d819-d3949224251b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final w = [0.49236201 0.24271295]\n",
            "Final b = -0.023120387837231953\n",
            "Initial Cost = 0.6928347469661926\n",
            "Final Cost = 0.6629540411186927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 7: Prediction\n",
        "def prediction(X, w, b, threshold=0.5):\n",
        "    z = np.dot(X, w) + b\n",
        "    probs = logistic_function(z)\n",
        "    return (probs >= threshold).astype(int)\n",
        "\n",
        "X_test = np.array([[0.5,1.0],[1.5,-0.5],[-0.5,-1.0]])\n",
        "w_test = np.array([1.0,-1.0])\n",
        "b_test = 0.0\n",
        "\n",
        "y_pred = prediction(X_test,w_test,b_test)\n",
        "print(\"Predictions =\", y_pred)\n",
        "\n",
        "assert np.array_equal(y_pred, np.array([0,1,1]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5sHWu8kmbvj",
        "outputId": "55451e04-27c5-4698-8237-23b6ce26f99d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions = [0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 8: Evaluation\n",
        "def evaluate_classification(y_true, y_pred):\n",
        "    TP = np.sum((y_true==1)&(y_pred==1))\n",
        "    TN = np.sum((y_true==0)&(y_pred==0))\n",
        "    FP = np.sum((y_true==0)&(y_pred==1))\n",
        "    FN = np.sum((y_true==1)&(y_pred==0))\n",
        "\n",
        "    precision = TP/(TP+FP) if TP+FP>0 else 0\n",
        "    recall = TP/(TP+FN) if TP+FN>0 else 0\n",
        "    f1 = 2*precision*recall/(precision+recall) if precision+recall>0 else 0\n",
        "\n",
        "    return np.array([[TN,FP],[FN,TP]]), precision, recall, f1\n",
        "\n",
        "y_true = np.array([1,0,1,0])\n",
        "y_pred = np.array([1,0,0,0])\n",
        "\n",
        "cm, p, r, f1 = evaluate_classification(y_true,y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"Precision =\", p)\n",
        "print(\"Recall =\", r)\n",
        "print(\"F1 Score =\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85-XyOabmh49",
        "outputId": "4cbe6012-bf41-4034-f719-f7aed119d948"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[2 0]\n",
            " [1 1]]\n",
            "Precision = 1.0\n",
            "Recall = 0.5\n",
            "F1 Score = 0.6666666666666666\n"
          ]
        }
      ]
    }
  ]
}